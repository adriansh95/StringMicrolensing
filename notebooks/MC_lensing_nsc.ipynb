{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7797ad1-37a9-4231-a891-0014790ef200",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-02T23:04:21.583360Z",
     "iopub.status.busy": "2024-09-02T23:04:21.583167Z",
     "iopub.status.idle": "2024-09-02T23:04:23.324679Z",
     "shell.execute_reply": "2024-09-02T23:04:23.323949Z",
     "shell.execute_reply.started": "2024-09-02T23:04:21.583338Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import traceback\n",
    "import time\n",
    "import logging\n",
    "\n",
    "base_dir = os.path.abspath('..')\n",
    "sys.path.append(base_dir)\n",
    "\n",
    "from dl import authClient as ac, queryClient as qc\n",
    "from tqdm import tqdm\n",
    "from utils.analyze_lensing import integrated_event_duration_posterior\n",
    "from utils import filtering\n",
    "from utils.kde_label import cluster_label_dataframe\n",
    "from utils.mc_backgrounds import synthesize_background\n",
    "from tqdm import tqdm\n",
    "from dl.helpers.utils import convert\n",
    "\n",
    "plt.rcParams['axes.facecolor']='white'\n",
    "plt.rcParams['savefig.facecolor']='white'\n",
    "read_dir = os.path.join(base_dir, \"results/12aug2024/\")\n",
    "fig_dir = os.path.join(base_dir, \"plots/2sep2024_MC/\")\n",
    "results_dir = os.path.join(base_dir, \"results/2sep2024_MC/\")\n",
    "log_dir = os.path.join(base_dir, \"logs/2sep2024_MC\")\n",
    "log_file = os.path.join(log_dir, \"MC_analysis.log\")\n",
    "\n",
    "for d in [fig_dir, results_dir, log_dir]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "logging.basicConfig(filename=log_file, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a922d082-2474-4d30-8bd6-375cf016eb97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-02T23:04:23.326078Z",
     "iopub.status.busy": "2024-09-02T23:04:23.325895Z",
     "iopub.status.idle": "2024-09-02T23:04:23.330200Z",
     "shell.execute_reply": "2024-09-02T23:04:23.329548Z",
     "shell.execute_reply.started": "2024-09-02T23:04:23.326062Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_query_string(i_batch, batch_size):\n",
    "    sub_query = f\"\"\"\n",
    "    SELECT objectid \n",
    "        FROM mydb://numbered_stable_stars_sep2 \n",
    "        WHERE row_number BETWEEN {i_batch * batch_size + 1} AND {(i_batch + 1) * batch_size}\n",
    "    \"\"\"\n",
    "    result = f\"\"\"\n",
    "    SELECT m.objectid, m.filter, m.mag_auto, m.magerr_auto, m.mjd, m.exposure, e.exptime\n",
    "        FROM nsc_dr2.meas AS m\n",
    "        INNER JOIN nsc_dr2.exposure AS e\n",
    "        ON e.exposure = m.exposure\n",
    "        WHERE m.objectid IN ({sub_query})\n",
    "    \"\"\"\n",
    "    return result\n",
    "\n",
    "def submit_job(i_batch, batch_size):\n",
    "    query = make_query_string(i_batch, batch_size)\n",
    "    result = qc.query(sql=query, async_=True, timeout=3600)\n",
    "    print(f\"Submit job #{i_batch}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6a5dab8-c1f4-49f4-9343-cc2e0977ddf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-02T23:04:23.331058Z",
     "iopub.status.busy": "2024-09-02T23:04:23.330916Z",
     "iopub.status.idle": "2024-09-02T23:04:23.421849Z",
     "shell.execute_reply": "2024-09-02T23:04:23.421387Z",
     "shell.execute_reply.started": "2024-09-02T23:04:23.331047Z"
    }
   },
   "outputs": [],
   "source": [
    "er_df = pd.read_parquet(f\"{read_dir}event_rates.parquet\")\n",
    "taus = np.geomspace(1e-4, 1e4, num=50)\n",
    "rates = er_df.loc[\"rate\"]\n",
    "bw = 0.13\n",
    "params = dict(achromatic = True, \n",
    "              factor_of_two = True)\n",
    "seed = 9047851\n",
    "rng = np.random.default_rng(seed=seed)\n",
    "logging.info(f\"Bandwidth = {bw}, params = {params}, taus = {taus}, rng_seed = {seed}, rng_state = {rng.bit_generator.state}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3696753-ac01-4596-a109-86fc1008bbca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-02T23:04:23.423057Z",
     "iopub.status.busy": "2024-09-02T23:04:23.422851Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/53 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submit job #0\n",
      "Submit job #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/53 [32:48<28:26:04, 1968.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submit job #2\n",
      "\n",
      "Total time: 1m:25.32s for 778.05 MB\n",
      "Processing batch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/53 [57:09<23:39:22, 1669.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submit job #3\n",
      "\n",
      "Total time: 1m:55.24s for 1017.38 MB\n",
      "Processing batch 2\n"
     ]
    }
   ],
   "source": [
    "batch_size = int(1e5)\n",
    "n_objects = 5279477\n",
    "num_batches = int(n_objects / batch_size) + 1\n",
    "poll_rate = 10\n",
    "batch_nums = np.arange(0, num_batches)\n",
    "filters = ['u', 'g', 'r', 'i', 'z', 'Y', 'VR']\n",
    "next_job_id = None\n",
    "\n",
    "for i_batch in tqdm(batch_nums):\n",
    "    try:\n",
    "        job_id = next_job_id\n",
    "        unimodal_filter_counts = np.zeros(len(filters))\n",
    "        background_filter_counts = np.zeros(len(filters))\n",
    "\n",
    "        if job_id is None:\n",
    "            job_id = submit_job(i_batch, batch_size)\n",
    "    \n",
    "        while qc.status(job_id) == \"EXECUTING\":\n",
    "            time.sleep(poll_rate)\n",
    "    \n",
    "        if i_batch != num_batches - 1:\n",
    "            next_job_id = submit_job(i_batch + 1, batch_size)\n",
    "    \n",
    "        if qc.status(job_id) == \"COMPLETED\":\n",
    "            # Get the data, filter out bands with fewer than 3 samples, sort by time\n",
    "            lcs = convert(qc.results(job_id))\n",
    "            print(f\"Processing batch {i_batch}\")\n",
    "            lcs = lcs.groupby(by=[\"objectid\", \"filter\"], \n",
    "                              sort=False).filter(lambda x: len(x) > 2)\n",
    "            lcs.sort_values(by=\"mjd\", inplace=True)\n",
    "\n",
    "            # Randomly inject synthetic \"flares\"\n",
    "            lcs = synthesize_background(lcs, rates, taus, rng)\n",
    "\n",
    "            # KDE label the result\n",
    "            cl = cluster_label_dataframe(lcs, bandwidth=bw)\n",
    "\n",
    "            # Save unstable, background, and unimodal IDs\n",
    "            lc_class_grouped = cl.groupby(by=\"objectid\",\n",
    "                                          sort=False,\n",
    "                                          as_index=False,\n",
    "                                          group_keys=False)\n",
    "            lightcurve_class_df = lc_class_grouped.apply(filtering.lightcurve_classifier)\n",
    "            lightcurve_class_fname = os.path.join(results_dir, \n",
    "                                                  f\"batch{i_batch}_lc_class_mc.parquet\")\n",
    "            lightcurve_class_df.columns = [lightcurve_class_df.columns[0], \"lightcurve_class\"]\n",
    "            lightcurve_class_df.to_parquet(lightcurve_class_fname)\n",
    "\n",
    "            # Filter out unstable looking stars\n",
    "            filtered_df = cl.groupby(by=\"objectid\", sort=False).filter(filtering.unstable_filter)\n",
    "\n",
    "            # Sort by MJD and filter out background events from stable stars\n",
    "            # Save Background Lightcurves\n",
    "            filtered_df.sort_values(by=\"mjd\", inplace=True)\n",
    "            g = filtered_df.groupby(\"objectid\", sort=False)\n",
    "            background_df = g.filter(lambda group: filtering.lens_filter(group, **params))\n",
    "            fname = f\"mc_lightcurves_batch{i_batch}.parquet\"\n",
    "            background_df.to_parquet(os.path.join(results_dir, fname))\n",
    "\n",
    "            # Filter out the stars that still look stable\n",
    "            unimodal_df = g.filter(filtering.unimodal_filter)\n",
    "\n",
    "            # Count number of stars and number of observations in each filter\n",
    "            unimodal_filter_counts = unimodal_df[\"filter\"].value_counts()\n",
    "            background_filter_counts = background_df[\"filter\"].value_counts()\n",
    "            agg_data = {f: np.array([unimodal_filter_counts.get(f, default=0), \n",
    "                                     background_filter_counts.get(f, default=0)]) for f in filters}\n",
    "            n_background = background_df[\"objectid\"].unique().size\n",
    "            n_unimodal = unimodal_df[\"objectid\"].unique().size\n",
    "            agg_data[\"n_objects\"] = np.array([n_unimodal, n_background])\n",
    "            idx = pd.MultiIndex.from_product([[i_batch], [\"Unimodal\", \"Background\"]])\n",
    "            aggregate_df = pd.DataFrame(data=agg_data, index=idx)\n",
    "            aggregate_df.to_parquet(os.path.join(results_dir, f\"batch{i_batch}_aggregates.parquet\"))\n",
    "            logging.info(f\"Processed batch #{i_batch}\")\n",
    "        elif qc.status(job_id) == \"ERROR\":\n",
    "            logging.error(f\"ERROR Batch {i_batch}: {qc.error(job_id)}\")\n",
    "            continue\n",
    "        else:\n",
    "            err_str = f\"\"\"\n",
    "            ERROR Batch {i_batch}: Something unexpected occurred. \n",
    "            job_id = {job_id}, status = {qc.status(job_id)}, \n",
    "            type = {type(job_id).__name__}, error = {qc.error(job_id)}\n",
    "            \"\"\"\n",
    "            logging.error(err_str)\n",
    "            continue\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Exception {e} Occurred batch #{i_batch}\")\n",
    "        err_str = f\"\"\"\n",
    "        ERROR Batch {i_batch}: Something unexpected occurred. \n",
    "        job_id = {job_id}\n",
    "        \"\"\"\n",
    "        logging.error(err_str)\n",
    "        logging.exception(\"Stack trace:\")\n",
    "        qc.abort(next_job_id)\n",
    "        next_job_id = None\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ea6649-185d-471e-9772-158528101901",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
